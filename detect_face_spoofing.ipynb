{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i-am-U-hyUn/Anti-Spoofing/blob/main/detect_face_spoofing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUncHQLdvskp",
        "outputId": "d09070c6-27c4-43bc-93ba-e82c7796bc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T98L8X-TqJqV",
        "outputId": "1149a75c-11cc-4e7c-f3bd-569486f3c76a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (5.29.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.4.26)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1060435 sha256=917459c8dd8704fe896fe0ad931ac591a3886da1b176674d0881168bf66192e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, insightface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed insightface-0.7.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python insightface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "import os\n",
        "import sys\n",
        "from typing import Type, Any, Callable, Union, List, Optional, Tuple\n",
        "\n",
        "\n",
        "# ResNet 모델 구현\n",
        "class BasicBlock(torch.nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[torch.nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., torch.nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = torch.nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = torch.nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(torch.nn.Module):\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[torch.nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., torch.nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = torch.nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = torch.nn.Conv2d(inplanes, width, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = torch.nn.Conv2d(width, width, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = torch.nn.Conv2d(width, planes * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block,\n",
        "        layers,\n",
        "        num_classes=1000,\n",
        "        zero_init_residual=False,\n",
        "        groups=1,\n",
        "        width_per_group=64,\n",
        "        replace_stride_with_dilation=None,\n",
        "        norm_layer=None,\n",
        "        fp16=False\n",
        "    ):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.fp16 = fp16\n",
        "        if norm_layer is None:\n",
        "            norm_layer = torch.nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = torch.nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = torch.nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return torch.nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        features = torch.flatten(x, 1)\n",
        "\n",
        "        logits = self.fc(features)\n",
        "        return (features, logits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def create_resnet50(num_classes=2):\n",
        "    \"\"\"자체 ResNet50 모델 생성 함수\"\"\"\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
        "\n",
        "\n",
        "# 표준 PyTorch ResNet50 생성 함수\n",
        "def create_torchvision_resnet50(num_classes=2):\n",
        "    \"\"\"표준 torchvision ResNet50 모델 생성 함수\"\"\"\n",
        "    from torchvision.models import resnet50\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "# 모델 로드 함수\n",
        "def load_model(model_path, model_type=\"resnet50\", num_classes=2):\n",
        "    if model_type == \"resnet50\":\n",
        "        model = create_resnet50(num_classes=num_classes)\n",
        "    elif model_type == \"swin_v2_b\":\n",
        "        from torchvision.models import swin_v2_b\n",
        "        model = swin_v2_b(pretrained=False)\n",
        "        model.head = torch.nn.Linear(model.head.in_features, num_classes)\n",
        "    elif model_type == \"mobilenet_v3_small\":\n",
        "        from torchvision.models import mobilenet_v3_small\n",
        "        model = mobilenet_v3_small(pretrained=False)\n",
        "        model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
        "    else:\n",
        "        print(f\"Unsupported model type: {model_type}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # 체크포인트 불러오기\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "        # 체크포인트 형식 확인 및 모델 state_dict 추출\n",
        "        if isinstance(checkpoint, dict):\n",
        "            if 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "                print(\"체크포인트에서 'state_dict' 키를 불러왔습니다.\")\n",
        "            elif 'state_dict_ema' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict_ema']\n",
        "                print(\"체크포인트에서 'state_dict_ema' 키를 불러왔습니다.\")\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "                print(\"체크포인트 전체를 state_dict로 사용합니다.\")\n",
        "        else:\n",
        "            state_dict = checkpoint\n",
        "            print(\"체크포인트를 직접 state_dict로 사용합니다.\")\n",
        "\n",
        "        # 'module.' 접두사 제거 (분산 학습의 경우)\n",
        "        new_state_dict = {}\n",
        "        for k, v in state_dict.items():\n",
        "            name = k\n",
        "            if k.startswith('module.'):\n",
        "                name = k[7:]  # module. 제거\n",
        "            new_state_dict[name] = v\n",
        "\n",
        "        # 모델에 가중치 로드 시도 (strict=False로 일부 누락된 키 허용)\n",
        "        model.load_state_dict(new_state_dict, strict=False)\n",
        "        print(\"모델 가중치 로드 성공 (일부 가중치는 누락될 수 있음)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"모델 로딩 중 오류 발생: {e}\")\n",
        "        print(\"ImageNet 사전 훈련된 모델로 대체...\")\n",
        "\n",
        "        # 표준 torchvision ResNet50 모델로 대체\n",
        "        model = create_torchvision_resnet50(num_classes)\n",
        "        print(\"ImageNet 사전 훈련된 ResNet50 모델로 대체되었습니다.\")\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# 얼굴 검출기 초기화\n",
        "def init_face_detector():\n",
        "    face_detector = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
        "    face_detector.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    return face_detector\n",
        "\n",
        "\n",
        "# 이미지 전처리\n",
        "def preprocess_image(image, face_only=False, face_detector=None, input_size=224):\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    if face_only and face_detector is not None:\n",
        "        # 얼굴 검출\n",
        "        faces = face_detector.get(image)\n",
        "        if faces and len(faces) > 0:\n",
        "            # 얼굴을 찾았을 때\n",
        "            face = faces[0]\n",
        "            bbox = face.bbox.astype(int)\n",
        "            # 20픽셀 확장\n",
        "            x1 = max(0, bbox[0] - 20)\n",
        "            y1 = max(0, bbox[1] - 20)\n",
        "            x2 = min(w, bbox[2] + 20)\n",
        "            y2 = min(h, bbox[3] + 20)\n",
        "            face_img = image[y1:y2, x1:x2]\n",
        "            if face_img.size == 0:\n",
        "                # 얼굴 영역이 없는 경우 중앙 크롭\n",
        "                return None, None, None\n",
        "            processed_img = face_img\n",
        "            face_bbox = (x1, y1, x2, y2)\n",
        "        else:\n",
        "            # 얼굴이 감지되지 않으면 중앙 크롭\n",
        "            if w >= 700 and h >= 700:\n",
        "                size = 500\n",
        "                center_x, center_y = w // 2, h // 2\n",
        "                x1 = max(0, center_x - size // 2)\n",
        "                y1 = max(0, center_y - size // 2)\n",
        "                x2 = min(w, center_x + size // 2)\n",
        "                y2 = min(h, center_y + size // 2)\n",
        "                processed_img = image[y1:y2, x1:x2]\n",
        "                face_bbox = (x1, y1, x2, y2)\n",
        "            else:\n",
        "                processed_img = image\n",
        "                face_bbox = (0, 0, w, h)\n",
        "    else:\n",
        "        # 전체 이미지 사용\n",
        "        processed_img = image\n",
        "        face_bbox = (0, 0, w, h)\n",
        "\n",
        "    # 이미지 변환\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((input_size, input_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    tensor_img = transform(processed_img).unsqueeze(0)\n",
        "    return tensor_img, processed_img, face_bbox\n",
        "\n",
        "\n",
        "# 추론 실행\n",
        "def run_inference(model, image, model_type=\"resnet50\"):\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            if model_type.startswith(\"mobilenet\") or model_type.startswith(\"shufflenet\"):\n",
        "                outputs = model(image)\n",
        "            else:\n",
        "                # ResNet 및 Swin 모델의 경우\n",
        "                try:\n",
        "                    features, outputs = model(image)\n",
        "                except:\n",
        "                    outputs = model(image)\n",
        "\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            return probabilities.numpy()[0]\n",
        "        except Exception as e:\n",
        "            print(f\"추론 중 오류 발생: {e}\")\n",
        "            # 오류 발생 시 기본값 반환 (50% 확률)\n",
        "            return np.array([0.5, 0.5])\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 설정\n",
        "    model_path = \"full_resnet50.pth\"  # 모델 경로 지정\n",
        "    model_type = \"resnet50\"  # 모델 유형에 따라 설정\n",
        "    face_only = False  # face_swin_v2_base.pth 사용 시 True로 설정\n",
        "    input_size = 224\n",
        "    image_path = \"1_dpi.png\"  # 현재 경로의 이미지 파일\n",
        "\n",
        "    # 모델 및 얼굴 검출기 로드\n",
        "    model = load_model(model_path, model_type, num_classes=2)\n",
        "    face_detector = init_face_detector() if face_only else None\n",
        "\n",
        "    print(f\"모델 로딩 완료: {model_type}\")\n",
        "\n",
        "    # 이미지 불러오기\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"오류: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
        "        return\n",
        "\n",
        "    frame = cv2.imread(image_path)\n",
        "    if frame is None:\n",
        "        print(f\"오류: 이미지를 읽을 수 없습니다: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # 원본 이미지 복사 (결과 표시용)\n",
        "    result_image = frame.copy()\n",
        "\n",
        "    # 이미지 전처리\n",
        "    tensor_img, processed_img, face_bbox = preprocess_image(\n",
        "        frame, face_only, face_detector, input_size)\n",
        "\n",
        "    if tensor_img is None:\n",
        "        print(\"얼굴을 감지할 수 없습니다.\")\n",
        "        cv2.putText(result_image, \"No face detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "        cv2.imshow('Face Anti-Spoofing Result', result_image)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "        return\n",
        "\n",
        "    # 추론\n",
        "    probs = run_inference(model, tensor_img, model_type)\n",
        "\n",
        "    # 결과 표시 (README에 따르면 spoof=1, live=0)\n",
        "    spoof_prob = probs[1]  # 스푸핑 확률\n",
        "    is_spoof = spoof_prob > 0.5\n",
        "    prob_text = f\"Spoof: {spoof_prob:.4f}, Live: {probs[0]:.4f}\"\n",
        "    result_text = \"SPOOF (위조)\" if is_spoof else \"LIVE (실제)\"\n",
        "    color = (0, 0, 255) if is_spoof else (0, 255, 0)\n",
        "\n",
        "    # 결과 이미지에 표시\n",
        "    cv2.putText(result_image, result_text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
        "    cv2.putText(result_image, prob_text, (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # 얼굴 영역 표시\n",
        "    if face_bbox is not None:\n",
        "        x1, y1, x2, y2 = face_bbox\n",
        "        cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 3)\n",
        "\n",
        "    # 처리된 얼굴 이미지 표시 (선택 사항)\n",
        "    if processed_img is not None and face_only:\n",
        "        h, w = processed_img.shape[:2]\n",
        "        h_result, w_result = result_image.shape[:2]\n",
        "\n",
        "        # 크기 조정 (결과 이미지의 1/4 크기로)\n",
        "        display_w = w_result // 4\n",
        "        display_h = int(h * display_w / w)\n",
        "        display_img = cv2.resize(processed_img, (display_w, display_h))\n",
        "\n",
        "        # 오른쪽 상단에 작은 이미지로 표시\n",
        "        h_display, w_display = display_img.shape[:2]\n",
        "        result_image[10:10+h_display, w_result-10-w_display:w_result-10] = display_img\n",
        "\n",
        "    # 최종 결과 출력\n",
        "    print(f\"분석 결과: {result_text}\")\n",
        "    print(f\"확률: {prob_text}\")\n",
        "\n",
        "    # 결과 이미지 표시\n",
        "    # cv2.imshow('Face Anti-Spoofing Result', result_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # 결과 이미지 저장 (선택 사항)\n",
        "    result_file = 'result1_dpi.jpg'\n",
        "    cv2.imwrite(result_file, result_image)\n",
        "    print(f\"결과 이미지가 저장되었습니다: {result_file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yRNBmwtq9Xv",
        "outputId": "15f6d60b-2f13-4697-8b12-e08cb1d5e93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "체크포인트에서 'state_dict' 키를 불러왔습니다.\n",
            "모델 가중치 로드 성공 (일부 가중치는 누락될 수 있음)\n",
            "모델 로딩 완료: resnet50\n",
            "분석 결과: LIVE (실제)\n",
            "확률: Spoof: 0.0755, Live: 0.9245\n",
            "결과 이미지가 저장되었습니다: result1_dpi.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# 이미지 열기\n",
        "img = Image.open(\"1.png\")\n",
        "\n",
        "# 원본 사이즈 확인\n",
        "original_size = img.size  # (2800, 2126)\n",
        "\n",
        "# 절반 크기로 리사이즈\n",
        "new_size = (original_size[0] // 2, original_size[1] // 2)\n",
        "resized_img = img.resize(new_size, Image.LANCZOS)\n",
        "\n",
        "# 저장\n",
        "resized_img.save(\"1_resized.png\")"
      ],
      "metadata": {
        "id": "1TvUwyDGQlkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# 원본 이미지 열기\n",
        "img = Image.open(\"1.png\")\n",
        "original_dpi = img.info.get(\"dpi\")\n",
        "\n",
        "print(f\"Original DPI: {original_dpi}\")\n",
        "\n",
        "# 절반 DPI로 설정\n",
        "new_dpi = (original_dpi[0] // 2, original_dpi[1] // 2)\n",
        "print(f\"New DPI: {new_dpi}\")\n",
        "\n",
        "# 저장\n",
        "img.save(\"1_dpi.png\", dpi=new_dpi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvsmuWIpaEIx",
        "outputId": "171a7b70-08a8-4e4c-e83b-2a43fd210c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DPI: (143.99259999999998, 143.99259999999998)\n",
            "New DPI: (71.0, 71.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UF2diNsXam8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}